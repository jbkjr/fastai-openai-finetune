{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Encoder\n",
    "Exactly as in pytorch port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ftfy\n",
    "import json\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_pairs(word):\n",
    "    \"\"\"\n",
    "    Return set of symbol pairs in a word.\n",
    "    word is represented as tuple of symbols (symbols being variable-length strings)\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs\n",
    "\n",
    "def text_standardize(text):\n",
    "    \"\"\"\n",
    "    fixes some issues the spacy tokenizer had on books corpus\n",
    "    also does some whitespace standardization\n",
    "    \"\"\"\n",
    "    text = text.replace('—', '-')\n",
    "    text = text.replace('–', '-')\n",
    "    text = text.replace('―', '-')\n",
    "    text = text.replace('…', '...')\n",
    "    text = text.replace('´', \"'\")\n",
    "    text = re.sub(r'''(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)''', r' \\1 ', text)\n",
    "    text = re.sub(r'\\s*\\n\\s*', ' \\n ', text)\n",
    "    text = re.sub(r'[^\\S\\n]+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "class TextEncoder(object):\n",
    "    \"\"\"\n",
    "    mostly a wrapper for a public python bpe tokenizer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_path, bpe_path):\n",
    "        self.nlp = spacy.load('en', disable=['parser', 'tagger', 'ner', 'textcat'])\n",
    "        self.encoder = json.load(open(encoder_path))\n",
    "        self.decoder = {v:k for k,v in self.encoder.items()}\n",
    "        merges = open(bpe_path, encoding='utf-8').read().split('\\n')[1:-1]\n",
    "        merges = [tuple(merge.split()) for merge in merges]\n",
    "        self.bpe_ranks = dict(zip(merges, range(len(merges))))\n",
    "        self.cache = {}\n",
    "\n",
    "    def bpe(self, token):\n",
    "        word = tuple(token[:-1]) + ( token[-1] + '</w>',)\n",
    "        if token in self.cache:\n",
    "            return self.cache[token]\n",
    "        pairs = get_pairs(word)\n",
    "\n",
    "        if not pairs:\n",
    "            return token+'</w>'\n",
    "\n",
    "        while True:\n",
    "            bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
    "            if bigram not in self.bpe_ranks:\n",
    "                break\n",
    "            first, second = bigram\n",
    "            new_word = []\n",
    "            i = 0\n",
    "            while i < len(word):\n",
    "                try:\n",
    "                    j = word.index(first, i)\n",
    "                    new_word.extend(word[i:j])\n",
    "                    i = j\n",
    "                except:\n",
    "                    new_word.extend(word[i:])\n",
    "                    break\n",
    "\n",
    "                if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
    "                    new_word.append(first+second)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_word.append(word[i])\n",
    "                    i += 1\n",
    "            new_word = tuple(new_word)\n",
    "            word = new_word\n",
    "            if len(word) == 1:\n",
    "                break\n",
    "            else:\n",
    "                pairs = get_pairs(word)\n",
    "        word = ' '.join(word)\n",
    "        if word == '\\n  </w>':\n",
    "            word = '\\n</w>'\n",
    "        self.cache[token] = word\n",
    "        return word\n",
    "\n",
    "    def encode(self, texts, verbose=True):\n",
    "        texts_tokens = []\n",
    "        if verbose:\n",
    "            for text in tqdm(texts, ncols=80, leave=False):\n",
    "                text = self.nlp(text_standardize(ftfy.fix_text(text)))\n",
    "                text_tokens = []\n",
    "                for token in text:\n",
    "                    text_tokens.extend([self.encoder.get(t, 0) for t in self.bpe(token.text.lower()).split(' ')])\n",
    "                texts_tokens.append(text_tokens)\n",
    "        else:\n",
    "            for text in texts:\n",
    "                text = self.nlp(text_standardize(ftfy.fix_text(text)))\n",
    "                text_tokens = []\n",
    "                for token in text:\n",
    "                    text_tokens.extend([self.encoder.get(t, 0) for t in self.bpe(token.text.lower()).split(' ')])\n",
    "                texts_tokens.append(text_tokens)\n",
    "        return texts_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = TextEncoder('model/encoder_bpe_40000.json', 'model/vocab_40000.bpe')\n",
    "encoder = text_encoder.encoder\n",
    "n_vocab = len(text_encoder.encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast ai loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/fas/radev/jbk54/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_PATH = Path('data/imdb_clas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(CLAS_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(CLAS_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels = np.load(CLAS_PATH/'tmp'/'lbl_trn.npy')\n",
    "val_labels = np.load(CLAS_PATH/'tmp'/'lbl_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(tok_trn.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(*splits, encoder):\n",
    "    encoded_splits = []\n",
    "    for split in splits:\n",
    "        fields = []\n",
    "        for field in split:\n",
    "            if isinstance(field[0], str):\n",
    "                field = encoder.encode(field)\n",
    "            fields.append(field)\n",
    "        encoded_splits.append(fields)\n",
    "    return encoded_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can skip from HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'xbos', 'xfld', '1', 'this', 'movie', 'gives', 'us', 'some', 't_up', 'wwii', 'history', 'along', 'with', 'some', 'touching', 'romance', ',', 'a', 'little', 'fantasy', 'and', 'meaningful', 'emotion', '-', 'and', 'beautiful', 'scenery', '.', 'nicholas', 'cage', 'never', 'fails', 'us', ',', 'and', 'here', 'again', 'does', 'a', 'great', 'job', '.', 'and', 'so', 'do', 'the', 'other', 'principle', 'characters', '.', 'one', 'key', 'charater', ',', 'the', 'physician', '/', 'father', 'played', 'by', 'john', 'hurd', ',', 'delivers', '(', 'to', 'his', 'daughter', ')', 'one', 'of', 'the', 'best', 'definitions', 'of', 'love', 'i', \"'ve\", 'ever', 'heard', '.', 'some', 'of', 'the', 'events', 'are', 'a', 'bit', 'too', 'coincidental', 'to', 'be', 'real', ',', 'but', 'i', 'excused', 'that', ',', 'knowing', 'that', 'this', 'is', 'partly', 'fairy', 'tale', 'and', 'fantacy', '.', 'my', 'wife', 'and', 'i', 'really', 'liked', 'the', 'film', '.', 'and', 'it', 'is', 'nice', 'to', 'watch', 'people', 'taking', 'the', 'risks', 'to', 'love', 'the', 'enemy', '.', 'one', 'man', 'who', 'left', 'the', 'theatre', 'near', 'us', 'said', 'to', 'his', 'wife', ',', '\"', 'now', 'that', \"'s\", 'the', 'way', 'to', 'wage', 'war', '!', '\"', 'i', 'think', 'you', \"'ll\", 'see', 'what', 'he', 'means', 'when', 'you', 'watch', 'the', 'italian', 'occupiers', 'of', 'this', 'lovely', 'greek', 'island', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tok_val[1347])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tried to get rid of \\n, xbos, xfld, and '1', so i could do it in a manner consistent with openAI's vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.asarray([' '.join(s[4:]) for s in tok_trn]) #join in order to make a list of strings in order to use encode_dataset\n",
    "tok_val = np.asarray([' '.join(s[4:]) for s in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this movie gives us some t_up wwii history along with some touching romance , a little fantasy and meaningful emotion - and beautiful scenery . nicholas cage never fails us , and here again does a great job . and so do the other principle characters . one key charater , the physician / father played by john hurd , delivers ( to his daughter ) one of the best definitions of love i 've ever heard . some of the events are a bit too coincidental to be real , but i excused that , knowing that this is partly fairy tale and fantacy . my wife and i really liked the film . and it is nice to watch people taking the risks to love the enemy . one man who left the theatre near us said to his wife , \" now that 's the way to wage war ! \" i think you 'll see what he means when you watch the italian occupiers of this lovely greek island .\n"
     ]
    }
   ],
   "source": [
    "print(tok_val[1347])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "((trX, trY), \n",
    " (vaX, vaY)) = encode_dataset((tok_trn, trn_labels), (tok_val, val_labels), encoder=text_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(CLAS_PATH/'tmp'/'trX.npy', trX)\n",
    "np.save(CLAS_PATH/'tmp'/'vaX.npy', vaX)\n",
    "np.save(CLAS_PATH/'tmp'/'trY.npy', trY)\n",
    "np.save(CLAS_PATH/'tmp'/'vaY.npy', vaY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "until HERE (on a re-run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX = np.load(CLAS_PATH/'tmp'/'trX.npy')\n",
    "vaX = np.load(CLAS_PATH/'tmp'/'vaX.npy')\n",
    "trY = np.load(CLAS_PATH/'tmp'/'trY.npy')\n",
    "vaY = np.load(CLAS_PATH/'tmp'/'vaY.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "[976, 240, 976, 1498, 1573, 6949, 4121, 239, 246, 18769, 1800, 18042, 617, 531, 23075, 239, 1203, 1218, 1428, 487, 11427, 246, 2672, 12808, 4817, 240, 872, 498, 3448, 239, 566, 13856, 3678, 1428, 276, 2229, 240, 525, 535, 599, 481, 7613, 3708, 603, 275, 246, 783, 2672, 12808, 4817, 544, 491, 481, 1736, 239, 520, 2191, 1662, 556, 1007, 3721, 2672, 12808, 4817, 763, 3796, 655, 240, 488, 4482, 5578, 1007, 4817, 239, 481, 4790, 640, 589, 5271, 240, 557, 640, 606, 239, 40477, 655, 640, 246, 2253, 498, 7613, 5555, 10063, 718, 889, 720, 980, 1981, 239, 11571, 640, 1686, 1938, 240, 488, 1892, 485, 1685, 9668, 2393, 1284, 240, 1457, 562, 909, 26992, 498, 775, 1376, 239, 246, 1322, 498, 11571, 11743, 9668, 2060, 488, 1592, 240, 522, 1779, 488, 1592, 240, 488, 4103, 909, 4001, 239, 2751, 481, 6848, 498, 720, 240, 1272, 498, 481, 9668, 640, 1120, 2311, 481, 1164, 4695, 239, 2207, 481, 25093, 6848, 498, 720, 2513, 669, 606, 788, 246, 956, 562, 481, 1420, 720, 240, 606, 1402, 5221, 271, 718, 928, 980, 525, 956, 694, 655, 257, 488, 1359, 240, 491, 1423, 566, 498, 481, 1469, 989, 587, 538, 2153, 485, 604, 694, 2926, 702, 1709, 239, 40477, 481, 4762, 18259, 485, 1715, 566, 1800, 702, 12801, 513, 500, 481, 5355, 240, 1007, 702, 12801, 575, 500, 481, 13489, 240, 488, 1007, 702, 13292, 513, 2930, 239, 544, 524, 2898, 13534, 522, 846, 257, 40477, 481, 5648, 2394, 2454, 980, 246, 21233, 271, 655, 640, 538, 775, 500, 481, 4121, 239, 481, 4883, 2454, 980, 246, 5688, 498, 1184, 500, 246, 12911, 5622, 488, 5389, 12241, 246, 2301, 498, 1909, 500, 246, 10843, 844, 239, 481, 6562, 13428, 500, 481, 5688, 544, 500, 481, 4121, 240, 568, 3362, 871, 11633, 1389, 531, 7600, 240, 488, 655, 544, 664, 1389, 3448, 239, 481, 4762, 544, 13013, 566, 260, 504, 260, 566, 239]\n"
     ]
    }
   ],
   "source": [
    "print(trX.shape)\n",
    "print(trX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(trX.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(trY[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder['_start_'] = len(encoder)\n",
    "#encoder['_delimiter_'] = len(encoder)\n",
    "encoder['_classify_'] = len(encoder)\n",
    "clf_token = encoder['_classify_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ctx = 512\n",
    "n_special = 2 #was 3 (no delimiter)\n",
    "max_len = 254 #it's truncated - if i calculate max_len like I did for RocStories, it gives me a full 512 n_ctx, which can't be handled by my single GPU\n",
    "n_ctx = min(max([len(x[:max_len]) for x in trX] + [len(x[:max_len]) for x in vaX]) + 2, n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = n_vocab + n_special + n_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(trX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_imdb(X1): #modified version of transform_roc from ROCStories implementation\n",
    "    n_batch = len(X1)\n",
    "    xmb = np.zeros((n_batch, n_ctx, 2), dtype=np.int32)\n",
    "    start = encoder['_start_']\n",
    "    for i, x in enumerate(X1):\n",
    "        x_new = [start] + x[:max_len] + [clf_token]\n",
    "        l = len(x_new)\n",
    "        xmb[i, :l, 0] = x_new\n",
    "    # Position information that is added to the input embeddings in the TransformerModel\n",
    "    xmb[:, :, 1] = np.arange(n_vocab + n_special, n_vocab + n_special + n_ctx)\n",
    "    return xmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX = transform_imdb(trX)\n",
    "vaX = transform_imdb(vaX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "print(trX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(trY)\n",
    "n_valid = len(vaY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch_train = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fastai.dataloader import DataLoader\n",
    "from fastai.dataset import *\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x,self.y=x,y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        return np.array(x),self.y[idx]\n",
    "\n",
    "    def __len__(self): return len(self.x)\n",
    "\n",
    "trn_ds = IMDBDataset(trX, trY)\n",
    "val_ds = IMDBDataset(vaX, vaY)\n",
    "trn_samp = SortishSampler(trX, key=lambda x: len(trX[x]), bs=8)\n",
    "val_samp = SortSampler(vaX, key=lambda x: len(vaX[x]))\n",
    "trn_dl = DataLoader(trn_ds, 8, num_workers=1, pad_idx=0, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, 8, num_workers=1, pad_idx=0, sampler=val_samp)\n",
    "PATH = Path('data')\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "direct from model_pytorch.py from pytorch port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "\n",
    "def swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "ACT_FNS = {\n",
    "    'relu': nn.ReLU,\n",
    "    'swish': swish,\n",
    "    'gelu': gelu\n",
    "}\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module in the OpenAI style (epsilon inside the square root).\"\n",
    "\n",
    "    def __init__(self, n_state, e=1e-5):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.g = nn.Parameter(torch.ones(n_state))\n",
    "        self.b = nn.Parameter(torch.zeros(n_state))\n",
    "        self.e = e\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.e)\n",
    "        return self.g * x + self.b\n",
    "\n",
    "\n",
    "class Conv1D(nn.Module):\n",
    "    def __init__(self, nf, rf, nx):\n",
    "        super(Conv1D, self).__init__()\n",
    "        self.rf = rf\n",
    "        self.nf = nf\n",
    "        if rf == 1:  # faster 1x1 conv\n",
    "            w = torch.empty(nx, nf)\n",
    "            nn.init.normal_(w, std=0.02)\n",
    "            self.w = Parameter(w)\n",
    "            self.b = Parameter(torch.zeros(nf))\n",
    "        else:  # was used to train LM\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.rf == 1:\n",
    "            size_out = x.size()[:-1] + (self.nf,)\n",
    "            x = torch.addmm(self.b, x.view(-1, x.size(-1)), self.w)\n",
    "            x = x.view(*size_out)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, nx, n_ctx, cfg, scale=False):\n",
    "        super(Attention, self).__init__()\n",
    "        n_state = nx  # in Attention: n_state=768 (nx=n_embd)\n",
    "        # [switch nx => n_state from Block to Attention to keep identical to TF implem]\n",
    "        assert n_state % cfg.n_head == 0\n",
    "        self.register_buffer('b', torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
    "        self.n_head = cfg.n_head\n",
    "        self.split_size = n_state\n",
    "        self.scale = scale\n",
    "        self.c_attn = Conv1D(n_state * 3, 1, nx)\n",
    "        self.c_proj = Conv1D(n_state, 1, nx)\n",
    "        self.attn_dropout = nn.Dropout(cfg.attn_pdrop)\n",
    "        self.resid_dropout = nn.Dropout(cfg.resid_pdrop)\n",
    "\n",
    "    def _attn(self, q, k, v):\n",
    "        w = torch.matmul(q, k)\n",
    "        if self.scale:\n",
    "            w = w / math.sqrt(v.size(-1))\n",
    "        w = w * self.b + -1e9 * (1 - self.b)  # TF implem method: mask_attn_weights\n",
    "        w = nn.Softmax(dim=-1)(w)\n",
    "        w = self.attn_dropout(w)\n",
    "        return torch.matmul(w, v)\n",
    "\n",
    "    def merge_heads(self, x):\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
    "        return x.view(*new_x_shape)  # in Tensorflow implem: fct merge_states\n",
    "\n",
    "    def split_heads(self, x, k=False):\n",
    "        new_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
    "        x = x.view(*new_x_shape)  # in Tensorflow implem: fct split_states\n",
    "        if k:\n",
    "            return x.permute(0, 2, 3, 1)\n",
    "        else:\n",
    "            return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_attn(x)\n",
    "        query, key, value = x.split(self.split_size, dim=2)\n",
    "        query = self.split_heads(query)\n",
    "        key = self.split_heads(key, k=True)\n",
    "        value = self.split_heads(value)\n",
    "        a = self._attn(query, key, value)\n",
    "        a = self.merge_heads(a)\n",
    "        a = self.c_proj(a)\n",
    "        a = self.resid_dropout(a)\n",
    "        return a\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_state, cfg):  # in MLP: n_state=3072 (4 * n_embd)\n",
    "        super(MLP, self).__init__()\n",
    "        nx = cfg.n_embd\n",
    "        self.c_fc = Conv1D(n_state, 1, nx)\n",
    "        self.c_proj = Conv1D(nx, 1, n_state)\n",
    "        self.act = ACT_FNS[cfg.afn]\n",
    "        self.dropout = nn.Dropout(cfg.resid_pdrop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.c_fc(x))\n",
    "        h2 = self.c_proj(h)\n",
    "        return self.dropout(h2)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_ctx, cfg, scale=False):\n",
    "        super(Block, self).__init__()\n",
    "        nx = cfg.n_embd\n",
    "        self.attn = Attention(nx, n_ctx, cfg, scale)\n",
    "        self.ln_1 = LayerNorm(nx)\n",
    "        self.mlp = MLP(4 * nx, cfg)\n",
    "        self.ln_2 = LayerNorm(nx)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = self.attn(x)\n",
    "        n = self.ln_1(x + a)\n",
    "        m = self.mlp(n)\n",
    "        h = self.ln_2(n + m)\n",
    "        return h\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\" Transformer model \"\"\"\n",
    "\n",
    "    def __init__(self, cfg, vocab=40990, n_ctx=512):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.vocab = vocab\n",
    "        self.embed = nn.Embedding(vocab, cfg.n_embd)\n",
    "        self.drop = nn.Dropout(cfg.embd_pdrop)\n",
    "        block = Block(n_ctx, cfg, scale=True)\n",
    "        self.h = nn.ModuleList([copy.deepcopy(block) for _ in range(cfg.n_layer)])\n",
    "\n",
    "        nn.init.normal_(self.embed.weight, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, x.size(-2), x.size(-1))\n",
    "        e = self.embed(x)\n",
    "        # Add the position information to the input embeddings\n",
    "        h = e.sum(dim=2)\n",
    "        for block in self.h:\n",
    "            h = block(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class LMHead(nn.Module):\n",
    "    \"\"\" Language Model Head for the transformer \"\"\"\n",
    "\n",
    "    def __init__(self, model, cfg):\n",
    "        super(LMHead, self).__init__()\n",
    "        self.n_embd = cfg.n_embd\n",
    "        embed_shape = model.embed.weight.shape\n",
    "        self.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\n",
    "        self.decoder.weight = model.embed.weight # Tied weights\n",
    "\n",
    "    def forward(self, h):\n",
    "        # Truncated Language modeling logits (we remove the last token)\n",
    "        h_trunc = h[:, :-1].contiguous().view(-1, self.n_embd)\n",
    "        lm_logits = self.decoder(h_trunc)\n",
    "        return lm_logits\n",
    "\n",
    "\n",
    "class MultipleChoiceHead(nn.Module):\n",
    "    \"\"\" Classifier Head for the transformer \"\"\"\n",
    "\n",
    "    def __init__(self, clf_token, cfg):\n",
    "        super(MultipleChoiceHead, self).__init__()\n",
    "        self.n_embd = cfg.n_embd\n",
    "        self.clf_token = clf_token\n",
    "        self.dropout = nn.Dropout2d(cfg.clf_pdrop)  # To reproduce the noise_shape parameter of TF implementation\n",
    "        self.linear = nn.Linear(cfg.n_embd, 1)\n",
    "\n",
    "        nn.init.normal_(self.linear.weight, std = 0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, h, x):\n",
    "        # Classification logits\n",
    "        clf_h = h.view(-1, self.n_embd)\n",
    "        flat = x[..., 0].contiguous().view(-1)\n",
    "        clf_h = clf_h[flat == self.clf_token, :]\n",
    "        clf_h = clf_h.view(-1, x.size(1), self.n_embd, 1)\n",
    "        # This double transposition is there to replicate the behavior\n",
    "        # of the noise_shape argument in the tensorflow\n",
    "        # implementation.  For more details, see\n",
    "        # https://github.com/huggingface/pytorch-openai-transformer-lm/issues/11\n",
    "        clf_h = self.dropout(clf_h.transpose(1, 2)).transpose(1, 2)\n",
    "        clf_h = clf_h.contiguous().view(-1, self.n_embd)\n",
    "        clf_logits = self.linear(clf_h)\n",
    "\n",
    "        return clf_logits.view(-1, x.size(1))\n",
    "\n",
    "\n",
    "class ClfHead(nn.Module):\n",
    "    \"\"\"Classification Head for the transformer\n",
    "    TODO: test this class.\"\"\"\n",
    "    def __init__(self, clf_token, cfg, n_class):\n",
    "        super(ClfHead, self).__init__()\n",
    "        self.n_embd = cfg.n_embd\n",
    "        self.clf_token = clf_token\n",
    "        self.dropout = nn.Dropout(cfg.clf_pdrop)\n",
    "        self.linear = nn.Linear(cfg.n_embd, n_class)\n",
    "\n",
    "        nn.init.normal_(self.linear.weight, std = 0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, h, x):\n",
    "        clf_h = h.view(-1, self.n_embd)\n",
    "        flat = x[..., 0].contiguous().view(-1)\n",
    "        clf_h = clf_h[flat == self.clf_token, :]\n",
    "        clf_h = self.dropout(clf_h)\n",
    "        clf_logits = self.linear(clf_h)\n",
    "\n",
    "        return clf_logits\n",
    "\n",
    "class SimilarityHead(nn.Module):\n",
    "    \"\"\" Similarity Head for the transformer\n",
    "        TODO: test this class.\"\"\"\n",
    "    def __init__(self, clf_token, cfg):\n",
    "        super(SimilarityHead, self).__init__()\n",
    "        self.n_embd = cfg.n_embd\n",
    "        self.clf_token = clf_token\n",
    "        self.dropout = nn.Dropout(cfg.clf_pdrop)\n",
    "        self.linear = nn.Linear(cfg.n_embd, 1)\n",
    "\n",
    "        nn.init.normal_(self.linear.weight, std = 0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, h, x):\n",
    "        sim_h = h.view(-1, self.n_embd)\n",
    "        flat = x[..., 0].contiguous().view(-1)\n",
    "        sim_h = sim_h[flat == self.clf_token, :]\n",
    "        sim_h = self.dropout(sim_h)\n",
    "        sim_h = sim_h.sum(dim = 1)\n",
    "        sim_logits = self.linear(sim_h)\n",
    "\n",
    "        return sim_logits\n",
    "\n",
    "class DoubleHeadModel(nn.Module):\n",
    "    \"\"\" Transformer with language model and task specific heads \"\"\"\n",
    "    def __init__(self, cfg, clf_token, task_head_type, vocab=40990, n_ctx=512):\n",
    "        super(DoubleHeadModel, self).__init__()\n",
    "        self.transformer = TransformerModel(cfg, vocab=vocab, n_ctx=n_ctx)\n",
    "        self.lm_head = LMHead(self.transformer, cfg)\n",
    "        if isinstance(task_head_type, str):\n",
    "            if task_head_type == 'multiple_choice':\n",
    "                self.task_head = MultipleChoiceHead(clf_token, cfg)\n",
    "            elif task_head_type == 'similarity':\n",
    "                self.task_head = SimilarityHead(clf_token, cfg)\n",
    "            elif task_head_type == 'inference':\n",
    "                # the three classes correspond to entailment, contradiction and neutral.\n",
    "                self.task_head = ClfHead(clf_token, cfg, 2) #WAS THREE, NOW 2 FOR IMDB\n",
    "            else:\n",
    "                raise ValueError(\"task_head_type is expected to be 'multiple_choice' \"\n",
    "                                 \"'similarity', 'inference' or ('classification', n_class) \"\n",
    "                                 f\"got {task_head_type}.\")\n",
    "        elif isinstance(task_head_type, collections.abc.Sequence) and len(task_head_type) == 2 and \\\n",
    "             task_head_type[0] == 'classification':\n",
    "            n_class = task_head_type[1]\n",
    "            self.task_head = ClfHead(clf_token, cfg, n_class)\n",
    "        else:\n",
    "            raise ValueError(\"task_head_type is expected to be 'multiple_choice' \"\n",
    "                             \"'similarity', 'inference' or ('classification', n_class) \"\n",
    "                             f\"got {task_head_type}.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.transformer(x)\n",
    "        lm_logits = self.lm_head(h)\n",
    "        task_logits = self.task_head(h, x)\n",
    "\n",
    "        return lm_logits, task_logits\n",
    "\n",
    "\n",
    "def load_openai_pretrained_model(model, n_ctx=-1, n_special=-1, n_transfer=12, n_embd=768, path='./model/',\n",
    "                                 path_names='./'):\n",
    "    # Load weights from TF model\n",
    "    print(\"Loading weights...\")\n",
    "    names = json.load(open(path_names + 'parameters_names.json'))\n",
    "    shapes = json.load(open(path + 'params_shapes.json'))\n",
    "    offsets = np.cumsum([np.prod(shape) for shape in shapes])\n",
    "    init_params = [np.load(path + 'params_{}.npy'.format(n)) for n in range(10)]\n",
    "    init_params = np.split(np.concatenate(init_params, 0), offsets)[:-1]\n",
    "    init_params = [param.reshape(shape) for param, shape in zip(init_params, shapes)]\n",
    "    if n_ctx > 0:\n",
    "        init_params[0] = init_params[0][:n_ctx]\n",
    "    if n_special > 0:\n",
    "        init_params[0] = np.concatenate(\n",
    "            [init_params[1],\n",
    "             (np.random.randn(n_special, n_embd) * 0.02).astype(np.float32),\n",
    "             init_params[0]\n",
    "             ], 0)\n",
    "    else:\n",
    "        init_params[0] = np.concatenate(\n",
    "            [init_params[1],\n",
    "             init_params[0]\n",
    "             ], 0)\n",
    "    del init_params[1]\n",
    "    if n_transfer == -1:\n",
    "        n_transfer = 0\n",
    "    else:\n",
    "        n_transfer = 1 + n_transfer * 12\n",
    "    init_params = [arr.squeeze() for arr in init_params]\n",
    "\n",
    "    try:\n",
    "        assert model.embed.weight.shape == init_params[0].shape\n",
    "    except AssertionError as e:\n",
    "        e.args += (model.embed.weight.shape, init_params[0].shape)\n",
    "        raise\n",
    "\n",
    "    model.embed.weight.data = torch.from_numpy(init_params[0])\n",
    "\n",
    "    for name, ip in zip(names[1:n_transfer], init_params[1:n_transfer]):\n",
    "        name = name[6:]  # skip \"model/\"\n",
    "        assert name[-2:] == \":0\"\n",
    "        name = name[:-2]\n",
    "        name = name.split('/')\n",
    "        pointer = model\n",
    "        for m_name in name:\n",
    "            if re.fullmatch(r'[A-Za-z]+\\d+', m_name):\n",
    "                l = re.split(r'(\\d+)', m_name)\n",
    "            else:\n",
    "                l = [m_name]\n",
    "            pointer = getattr(pointer, l[0])\n",
    "            if len(l) >= 2:\n",
    "                num = int(l[1])\n",
    "                pointer = pointer[num]\n",
    "        try:\n",
    "            assert pointer.shape == ip.shape\n",
    "        except AssertionError as e:\n",
    "            e.args += (pointer.shape, ip.shape)\n",
    "            raise\n",
    "        pointer.data = torch.from_numpy(ip)\n",
    "\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "DEFAULT_CONFIG = dotdict({\n",
    "    'n_embd': 768,\n",
    "    'n_head': 12,\n",
    "    'n_layer': 12,\n",
    "    'embd_pdrop': 0.1,\n",
    "    'attn_pdrop': 0.1,\n",
    "    'resid_pdrop': 0.1,\n",
    "    'afn': 'gelu',\n",
    "    'clf_pdrop': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_model = DoubleHeadModel(DEFAULT_CONFIG, clf_token, 'inference', vocab, n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights...\n"
     ]
    }
   ],
   "source": [
    "load_openai_pretrained_model(dh_model.transformer, n_ctx=n_ctx, n_special=n_special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "def warmup_cosine(x, warmup=0.002):\n",
    "    s = 1 if x <= warmup else 0\n",
    "    return s*(x/warmup) + (1-s)*(0.5 * (1 + torch.cos(math.pi * x)))\n",
    "\n",
    "def warmup_constant(x, warmup=0.002):\n",
    "    s = 1 if x <= warmup else 0\n",
    "    return s*(x/warmup) + (1-s)*1\n",
    "\n",
    "def warmup_linear(x, warmup=0.002):\n",
    "    s = 1 if x <= warmup else 0\n",
    "    return (s*(x/warmup) + (1-s))*(1-x)\n",
    "\n",
    "SCHEDULES = {\n",
    "    'warmup_cosine':warmup_cosine,\n",
    "    'warmup_constant':warmup_constant,\n",
    "    'warmup_linear':warmup_linear,\n",
    "}\n",
    "\n",
    "\n",
    "class OpenAIAdam(Optimizer):\n",
    "    \"\"\"Implements Open AI version of Adam algorithm with weight decay fix.\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr, schedule, warmup, t_total,\n",
    "                 b1=0.9, b2=0.999, e=1e-8, l2=0,\n",
    "                 vector_l2=False, max_grad_norm=-1, **kwargs):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if schedule not in SCHEDULES:\n",
    "            raise ValueError(\"Invalid schedule parameter: {}\".format(schedule))\n",
    "        if not 0 <= warmup:\n",
    "            raise ValueError(\"Invalid warmup: {}\".format(warmup))\n",
    "        if not 0.0 <= b1 < 1.0:\n",
    "            raise ValueError(\"Invalid b1 parameter: {}\".format(b1))\n",
    "        if not 0.0 <= b2 < 1.0:\n",
    "            raise ValueError(\"Invalid b2 parameter: {}\".format(b2))\n",
    "        if not 0.0 <= e:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(e))\n",
    "        defaults = dict(lr=lr, schedule=schedule, warmup=warmup, t_total=t_total,\n",
    "                        b1=b1, b2=b2, e=e, l2=l2, vector_l2=vector_l2,\n",
    "                        max_grad_norm=max_grad_norm)\n",
    "        super(OpenAIAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['b1'], group['b2']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                # Add grad clipping\n",
    "                if group['max_grad_norm'] > 0:\n",
    "                    clip_grad_norm_(p, group['max_grad_norm'])\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                denom = exp_avg_sq.sqrt().add_(group['e'])\n",
    "\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "\n",
    "                schedule_fct = SCHEDULES[group['schedule']]\n",
    "                lr_scheduled = group['lr'] * schedule_fct(state['step']/group['t_total'], group['warmup'])\n",
    "                step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1\n",
    "\n",
    "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "                # Add weight decay at the end (fixed version)\n",
    "                if (len(p.size()) > 1 or group['vector_l2']) and group['l2'] > 0:\n",
    "                    p.data.add_(-lr_scheduled * group['l2'], p.data)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(OpenAIAdam, lr=6.25e-5, schedule='warmup_linear', warmup=0.002, t_total=9375)\n",
    "#t_total changed to account for changed number of minibatches in imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(md, SingleModel(to_gpu(dh_model)), opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBStepper():\n",
    "    def __init__(self, m, opt, crit, clip=0, reg_fn=None, fp16=False, loss_scale=1):\n",
    "        self.m,self.opt,self.crit,self.clip,self.reg_fn = m,opt,crit,clip,reg_fn\n",
    "        self.fp16 = fp16\n",
    "        self.reset(True)\n",
    "        if self.fp16: self.fp32_params = copy_model_to_fp32(m, opt)\n",
    "        self.loss_scale = loss_scale\n",
    "\n",
    "    def reset(self, train=True):\n",
    "        if train: apply_leaf(self.m, set_train_mode)\n",
    "        else: self.m.eval()\n",
    "        if hasattr(self.m, 'reset'):\n",
    "            self.m.reset()\n",
    "            if self.fp16: self.fp32_params = copy_model_to_fp32(self.m, self.opt)\n",
    "\n",
    "    def step(self, xs, y, epoch):\n",
    "        xtra = []\n",
    "        lm_logits, task_logits = self.m(*xs)\n",
    "        #loss = raw_loss = self.crit(lm_logits)\n",
    "        #if isinstance(output,tuple): lm_logits, task_logits = output\n",
    "        if self.fp16: self.m.zero_grad()\n",
    "        else: self.opt.zero_grad() \n",
    "        loss = raw_loss = self.crit(lm_logits, task_logits, *xs, y)\n",
    "        if self.loss_scale != 1: assert(self.fp16); loss = loss*self.loss_scale\n",
    "        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n",
    "        loss.backward()\n",
    "        if self.fp16: update_fp32_grads(self.fp32_params, self.m)\n",
    "        if self.loss_scale != 1:\n",
    "            for param in self.fp32_params: param.grad.data.div_(self.loss_scale)\n",
    "        if self.clip:   # Gradient clipping\n",
    "            if IS_TORCH_04: nn.utils.clip_grad_norm_(trainable_params_(self.m), self.clip)\n",
    "            else: nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
    "        if 'wd' in self.opt.param_groups[0] and self.opt.param_groups[0]['wd'] != 0: \n",
    "            #Weight decay out of the loss. After the gradient computation but before the step.\n",
    "            for group in self.opt.param_groups:\n",
    "                lr, wd = group['lr'], group['wd']\n",
    "                for p in group['params']:\n",
    "                    if p.grad is not None: p.data = p.data.add(-wd * lr, p.data)\n",
    "        self.opt.step()\n",
    "        if self.fp16: \n",
    "            copy_fp32_to_model(self.m, self.fp32_params)\n",
    "            torch.cuda.synchronize()\n",
    "        return torch_item(raw_loss.data)\n",
    "    \n",
    "    def evaluate(self, xs, y):\n",
    "        lm_logits, task_logits = self.m(*xs)\n",
    "        return task_logits, self.crit(lm_logits, task_logits, *xs, y)\n",
    "\n",
    "def CLFLoss(lm_logits, clf_logits, X, Y, lm_coef=0.5):\n",
    "    x_shifted = X[:, 1:, 0].contiguous().view(-1)  # Shape: 252\n",
    "    \"\"\"M = torch.ne(X[:, :, :, 0] , T(torch.zeros(X.size()[:-1], dtype=torch.long))).to(torch.float)\n",
    "    M = M.view(-1, M.size(2))\n",
    "    lm_losses = F.cross_entropy(lm_logits, x_shifted, reduction='none')\n",
    "    lm_losses = lm_losses.view(X.size(0) * X.size(1), X.size(2) - 1)\n",
    "    lm_losses = lm_losses * M[:, 1:]\n",
    "    lm_losses = lm_losses.sum(1) / torch.sum(M[:, 1:], 1)\n",
    "    \n",
    "    clf_losses = F.cross_entropy(clf_logits, Y, reduction='none')\"\"\"\n",
    "    \n",
    "    lm_losses = F.cross_entropy(lm_logits, x_shifted, ignore_index=0, reduction='elementwise_mean')\n",
    "    clf_losses = F.cross_entropy(clf_logits, Y.view(Y.size(0)*Y.size(1)), reduction='sum')\n",
    "    \n",
    "    train_loss = clf_losses + lm_coef * lm_losses\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.crit = CLFLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e74f9d464f645fa86c1fcfdcd7a4ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      3.540213   3.607768   0.55363   \n",
      "    1      2.910129   3.636233   0.55403                       \n",
      "    2      2.737276   3.835509   0.55358                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.8355092220306397, 0.55358]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(6.25e-5, 3, cycle_len=1, stepper=IMDBStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
